{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/un1tz3r0/anythingdiffusion/blob/main/Anything_Diffusion_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hBAjQO1kiEW"
      },
      "source": [
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=fine_tuning_your_own_diffusion_model_using_clip_retrieval_ipynb)\n",
        "\n",
        "# [AnythingDiffusion](https://github.com/un1tz3r0/anythingdiffusion/)\n",
        "#### by [un1tz3r0](https://linktr.ee/un1tz3r0), based on a notebook by [Alex Spirin](https://twitter.com/devdef).\n",
        "\n",
        "A simple colab to fine-tune your very own diffusion models on images from CLIP-retrieval which are nearby a text prompt, and automatically resume training from the last checkpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ8BNzApp_Xk"
      },
      "source": [
        "# Configure\n",
        "\n",
        "Needs 16gb GPU RAM\n",
        "\n",
        "Works in colab pro and on kaggle "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown This is the name of the subdirectory where your custom model snapshots and logs will be dumped during the training:\n",
        "\n",
        "custom_model_name = \"paisleydiffusion\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Everything, including the dataset and the models and model progress and other training output will be on your drive in <tt>Disco_Diffusion/Fine_Tuning/<error>custom_model_name</error>/</tt>\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M-QtGUPcFsdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ihEN_8wKEXWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtMv2MEzSzjN",
        "outputId": "4ccaca97-4bb2-4e1f-e8a2-65d71585c8c0",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@markdown Connect with google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-fL3fb8wpxZ",
        "outputId": "a9545b62-a012-4296-fdce-60b78d0c2933",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'guided-diffusion-sxela'...\n",
            "remote: Enumerating objects: 154, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 154 (delta 60), reused 48 (delta 43), pack-reused 64\u001b[K\n",
            "Receiving objects: 100% (154/154), 87.56 KiB | 4.61 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "/content/guided-diffusion-sxela\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/guided-diffusion-sxela\n",
            "Collecting blobfile>=1.0.5\n",
            "  Downloading blobfile-1.3.1-py3-none-any.whl (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from guided-diffusion==0.0.0) (1.12.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from guided-diffusion==0.0.0) (4.64.0)\n",
            "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.7/dist-packages (from blobfile>=1.0.5->guided-diffusion==0.0.0) (3.7.1)\n",
            "Collecting xmltodict~=0.12.0\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting urllib3~=1.25\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting pycryptodomex~=3.8\n",
            "  Downloading pycryptodomex-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->guided-diffusion==0.0.0) (4.1.1)\n",
            "Installing collected packages: xmltodict, urllib3, pycryptodomex, blobfile, guided-diffusion\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Running setup.py develop for guided-diffusion\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.11 which is incompatible.\u001b[0m\n",
            "Successfully installed blobfile-1.3.1 guided-diffusion-0.0.0 pycryptodomex-3.15.0 urllib3-1.26.11 xmltodict-0.12.0\n"
          ]
        }
      ],
      "source": [
        "#@markdown Download and install guided diffusion\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/Sxela/guided-diffusion-sxela\n",
        "%cd /content/guided-diffusion-sxela\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Define some helpers and create directories\n",
        "\n",
        "import pathlib, subprocess, os, sys, ipykernel\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  is_colab = True\n",
        "except:\n",
        "  is_colab = False\n",
        "\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "def createParent(filepath):\n",
        "    os.makedirs(os.path.dirname(os.path.abspath(filepath)), exist_ok=True)\n",
        "\n",
        "def pipi(*modulestrs):\n",
        "    res = subprocess.run(['pip', 'install', *modulestrs], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir=None, filename=None):\n",
        "    if outputdir != None:\n",
        "      res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    elif filename != None:\n",
        "      res = subprocess.run(['wget', url, '-O', f'{filename}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "      res = subprocess.run(['wget', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "google_drive = True\n",
        "\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        rootPath = '/content/drive/MyDrive/Disco_Diffusion'\n",
        "    else:\n",
        "        rootPath = '/content'\n",
        "else:\n",
        "    rootPath = os.getcwd()\n",
        "\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "def createParent(filepath):\n",
        "    os.makedirs(os.path.dirname(os.path.abspath(filepath)), exist_ok=True)\n",
        "\n",
        "# set up some folders based on the custom_model_name in the form for this cell...\n",
        "\n",
        "finetuningRoot = f\"{rootPath}/Fine_Tuning/{custom_model_name}\"\n",
        "createPath(f\"{finetuningRoot}\")\n",
        "\n",
        "datasetRoot = f\"{finetuningRoot}/dataset\"\n",
        "createPath(f\"{datasetRoot}\")\n",
        "\n",
        "trainingRoot = f\"{finetuningRoot}/training\"\n",
        "createPath(f\"{trainingRoot}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "cellView": "form",
        "id": "4OMuXyRFen5l",
        "outputId": "c7053cbb-8645-4f07-d0b5-2412c9191358"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a2bb082037d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# set up some folders based on the custom_model_name in the form for this cell...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mfinetuningRoot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{rootPath}/Fine_Tuning/{custom_model_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mcreatePath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{finetuningRoot}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'custom_model_name' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7kNS0XQBIY1"
      },
      "source": [
        "# Get images to train on using CLIP-retrieval\n",
        "\n",
        "Generate a dataset from images retrieved by proximity to a text prompt in the CLIP latent space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmGjWRMM9_VY",
        "outputId": "59a15b05-040e-44a3-de2a-ace2c275d570",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset directory: /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/paisleydiffusion/dataset\n",
            "Dataset already exists, skipping clip-retrieval...\n"
          ]
        }
      ],
      "source": [
        "# create the dataset using clip retrieval and aiohttp/aiomultiprocessing to download in paralell\n",
        "\n",
        "dataset_text_prompt = \"paisley\" #@param {type: \"string\"}\n",
        "dataset_fetch_size = 5000 #@param {type: \"integer\"}\n",
        "dataset_crop_count = 2000 #@param {type: \"integer\"}\n",
        "\n",
        "datasetPath = f'{datasetRoot}'\n",
        "if pathlib.Path(datasetPath).exists():\n",
        "  print(f\"Dataset directory: {datasetPath}\\nDataset already exists, skipping clip-retrieval...\")\n",
        "else:\n",
        "  createPath(datasetPath)\n",
        "\n",
        "if not pathlib.Path(datasetPath).exists():# or len(list(pathlib.Path(datasetPath).iterdir())) < 3':\n",
        "  print(f\"Creating new dataset from clip-retrieval for the prompt: '{dataset_text_prompt}'\")\n",
        "  try:\n",
        "    datasetOutPath=datasetPath+\"/out\"\n",
        "    createPath(datasetOutPath)\n",
        "    createPath(datasetPath+\"/crop\")\n",
        "\n",
        "    pipi(\"click\", \"clip-retrieval\", \"img2dataset\", \"aiomultiprocess\", \"aiohttp\", \"aiofile\")\n",
        "    wget(\"https://gist.githubusercontent.com/un1tz3r0/a18ba5cf48228ca5cabc58d1d556ad0b/raw/2c5f96e27ee077c8e218925380829a72770b0dd2/clipfetch.py\", filename=\"clipfetch.py\")\n",
        "    wget(\"https://raw.githubusercontent.com/un1tz3r0/pixelscapes-dataset/main/randomcrops.py\", filename=\"randomcrops.py\")\n",
        "\n",
        "    dataset_text_prompt_q = shlex.data\n",
        "    !python3 clipfetch.py $dataset_text_prompt_q $datasetOutPath_q --count $dataset_fetch_size --timeout 5 --paralell 25\n",
        "\n",
        "    print(f\"Generating {dataset_crop_count} cropped squares from source images in {datasetOutPath}...\")\n",
        "\n",
        "    import sys\n",
        "    sys.path.append(pathlib.Path(\"./\").absolute())\n",
        "    import randomcrops\n",
        "    randomcrops.randomcrops(datasetPath+\"/out\", datasetPath+\"/crop\", dataset_crop_count, 256, weighting=0.0, withclasses=False, statusinterval=50)\n",
        "\n",
        "    datasetPath = datasetRoot+\"/crop\"\n",
        "    print(f\"Done creating dataset from clip-retrieval in: {datasetPath}\")\n",
        "    #touch(datasetPath+\"/.completed\")\n",
        "  except Exception as err:\n",
        "    import traceback as tb\n",
        "    tb.print_exc(err)\n",
        "    raise err\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV2gIxZhw2me"
      },
      "source": [
        "# <big><big>Fine Tune</big></big>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqBBkqPjqESf"
      },
      "source": [
        "This will run almost forever, but you should start checking your results at around ~50k iterations. Good results begin to appear at 100-200k iterations, depending on your dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "apH5i0hTqz1y",
        "outputId": "952e7b88-a151-4e47-b6fa-7b69b9e2d09d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-63e7293571cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mMODEL_FLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--image_size 256 --num_channels 128 --num_res_blocks 2 --num_heads 1 --learn_sigma True --use_scale_shift_norm False --attention_resolutions 16\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mDIFFUSION_FLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--diffusion_steps 1000 --noise_schedule linear --rescale_learned_sigmas False --rescale_timesteps False --use_scale_shift_norm False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mRESUME_CHECKPOINT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingRoot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{trainingRoot}/lsun_uncond_100M_1200K_bs128.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https://openaipublic.blob.core.windows.net/diffusion/march-2021/lsun_uncond_100M_1200K_bs128.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mTRAIN_FLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"--lr 2e-5 --batch_size 4 --save_interval 1000 --log_interval 50  --resume_checkpoint {shlex.quote(RESUME_CHECKPOINT)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#change to point to your dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainingRoot' is not defined"
          ]
        }
      ],
      "source": [
        "#@markdown # Do the run...\n",
        "\n",
        "import shlex\n",
        "\n",
        "def latest_checkpoint(checkpoint_path, default_model, default_model_url):\n",
        "  import pathlib, os\n",
        "  try:\n",
        "    def kf(f):\n",
        "      return f.lstat().st_mtime\n",
        "    f = str(list(sorted(list(pathlib.Path(checkpoint_path).glob(\"ema_0.9999_*.pt\")), key=kf))[-1])\n",
        "    print(f\"Resuming from latest checkpoint found: {f}\")\n",
        "    return f\n",
        "  except Exception as err:\n",
        "    print(f\"Error finding latest checkpoint in {checkpoint_path}: {err}\")\n",
        "    print(f\"Resuming from default pretrained model: {default_model}\")\n",
        "    if not pathlib.Path(default_model).exists():\n",
        "      print(f\"Downloading default pretrained model from: {default_model_url}\")\n",
        "      wget(default_model_url, filename=default_model)\n",
        "      print(f\"Done!\")\n",
        "    else:\n",
        "      print(f\"Default pretrained model found at: {default_model}\")\n",
        "      print(f\"Skipping model download.\")\n",
        "    return default_model\n",
        "\n",
        "\n",
        "#!wget https://openaipublic.blob.core.windows.net/diffusion/march-2021/lsun_uncond_100M_1200K_bs128.pt\n",
        "MODEL_FLAGS=\"--image_size 256 --num_channels 128 --num_res_blocks 2 --num_heads 1 --learn_sigma True --use_scale_shift_norm False --attention_resolutions 16\"\n",
        "DIFFUSION_FLAGS=\"--diffusion_steps 1000 --noise_schedule linear --rescale_learned_sigmas False --rescale_timesteps False --use_scale_shift_norm False\"\n",
        "RESUME_CHECKPOINT=latest_checkpoint(trainingRoot, f\"{trainingRoot}/lsun_uncond_100M_1200K_bs128.pt\", 'https://openaipublic.blob.core.windows.net/diffusion/march-2021/lsun_uncond_100M_1200K_bs128.pt')\n",
        "TRAIN_FLAGS=f\"--lr 2e-5 --batch_size 4 --save_interval 1000 --log_interval 50  --resume_checkpoint {shlex.quote(RESUME_CHECKPOINT)}\"\n",
        "DATASET_PATH=shlex.quote(datasetPath) #change to point to your dataset path \n",
        "%cd /content/guided-diffusion-sxela\n",
        "!OPENAI_LOGDIR=$trainingRoot python scripts/image_train.py --data_dir $DATASET_PATH $MODEL_FLAGS $DIFFUSION_FLAGS $TRAIN_FLAGS"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Anything Diffusion: Fine-Tuning Your Own Diffusion Model Using CLIP-Retrieval.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}