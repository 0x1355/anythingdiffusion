{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/un1tz3r0/anythingdiffusion/blob/main/Anything_Diffusion_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hBAjQO1kiEW"
      },
      "source": [
        "![visitors](https://visitor-badge.glitch.me/badge?page_id=fine_tuning_your_own_diffusion_model_using_clip_retrieval_ipynb)\n",
        "\n",
        "# [AnythingDiffusion](https://github.com/un1tz3r0/anythingdiffusion/)\n",
        "#### by [un1tz3r0](https://linktr.ee/un1tz3r0), based on a notebook by [Alex Spirin](https://twitter.com/devdef).\n",
        "\n",
        "A simple colab to fine-tune your very own diffusion models on images from CLIP-retrieval which are nearby a text prompt, and automatically resume training from the last checkpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ8BNzApp_Xk"
      },
      "source": [
        "# Configure\n",
        "\n",
        "Needs 16gb GPU RAM\n",
        "\n",
        "Works in colab pro and on kaggle "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown This is the name of the subdirectory where your custom model snapshots and logs will be dumped during the training:\n",
        "\n",
        "custom_model_name = \"spiraldiffusion\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Everything, including the dataset and the models and model progress and other training output will be on your drive in <tt>Disco_Diffusion/Fine_Tuning/<error>custom_model_name</error>/</tt>\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M-QtGUPcFsdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ihEN_8wKEXWG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "EtMv2MEzSzjN",
        "outputId": "53e5ba58-b08d-45b6-a7ae-f796b39ef88e",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d0dcad082671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 120\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@markdown Connect with google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-fL3fb8wpxZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Download and install guided diffusion\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/Sxela/guided-diffusion-sxela\n",
        "%cd /content/guided-diffusion-sxela\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Define some helpers and create directories\n",
        "\n",
        "import pathlib, subprocess, os, sys, ipykernel\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  is_colab = True\n",
        "except:\n",
        "  is_colab = False\n",
        "\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "def createParent(filepath):\n",
        "    os.makedirs(os.path.dirname(os.path.abspath(filepath)), exist_ok=True)\n",
        "\n",
        "def pipi(*modulestrs):\n",
        "    res = subprocess.run(['pip', 'install', *modulestrs], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir=None, filename=None):\n",
        "    if outputdir != None:\n",
        "      res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    elif filename != None:\n",
        "      res = subprocess.run(['wget', url, '-O', f'{filename}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "      res = subprocess.run(['wget', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "google_drive = True\n",
        "\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        rootPath = '/content/drive/MyDrive/Disco_Diffusion'\n",
        "    else:\n",
        "        rootPath = '/content'\n",
        "else:\n",
        "    rootPath = os.getcwd()\n",
        "\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "def createParent(filepath):\n",
        "    os.makedirs(os.path.dirname(os.path.abspath(filepath)), exist_ok=True)\n",
        "\n",
        "# set up some folders based on the custom_model_name in the form for this cell...\n",
        "\n",
        "finetuningRoot = f\"{rootPath}/Fine_Tuning/{custom_model_name}\"\n",
        "createPath(f\"{finetuningRoot}\")\n",
        "\n",
        "datasetRoot = f\"{finetuningRoot}/dataset\"\n",
        "createPath(f\"{datasetRoot}\")\n",
        "\n",
        "trainingRoot = f\"{finetuningRoot}/training\"\n",
        "createPath(f\"{trainingRoot}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OMuXyRFen5l",
        "outputId": "3f4c572d-00e1-4a0e-e762-e45302b75744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7kNS0XQBIY1"
      },
      "source": [
        "# Get images to train on using CLIP-retrieval\n",
        "\n",
        "Generate a dataset from images retrieved by proximity to a text prompt in the CLIP latent space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmGjWRMM9_VY",
        "outputId": "6b2a7fa2-0389-48c9-bbe6-e0c4e99c628e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset directory: /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset\n",
            "Dataset already exists, skipping clip-retrieval...\n",
            "Creating new dataset from clip-retrieval for the prompt: 'spiral'\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting clip-retrieval\n",
            "  Downloading clip_retrieval-2.34.2-py3-none-any.whl (338 kB)\n",
            "Collecting img2dataset\n",
            "  Downloading img2dataset-1.32.0-py3-none-any.whl (34 kB)\n",
            "Collecting aiomultiprocess\n",
            "  Downloading aiomultiprocess-0.9.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (3.8.1)\n",
            "Collecting aiofile\n",
            "  Downloading aiofile-3.8.1.tar.gz (18 kB)\n",
            "Collecting requests<3,>=2.27.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting fire<0.5.0,>=0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "Collecting fsspec==2022.1.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "Collecting open-clip-torch<2.0.0,>=1.0.1\n",
            "  Downloading open_clip_torch-1.3.0-py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: torchvision<2,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (0.13.0+cu113)\n",
            "Collecting faiss-cpu<2,>=1.7.2\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Requirement already satisfied: prometheus-client<1,>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (0.14.1)\n",
            "Collecting clip-anytorch<3,>=2.3.1\n",
            "  Downloading clip_anytorch-2.4.0-py3-none-any.whl (1.4 MB)\n",
            "Collecting autofaiss<3,>=2.9.6\n",
            "  Downloading autofaiss-2.15.1-py3-none-any.whl (69 kB)\n",
            "Collecting multilingual-clip<2,>=1.0.10\n",
            "  Downloading multilingual_clip-1.0.10-py3-none-any.whl (20 kB)\n",
            "Collecting webdataset<0.2,>=0.1.103\n",
            "  Downloading webdataset-0.1.103-py3-none-any.whl (47 kB)\n",
            "Collecting flask-cors<4,>=3.0.10\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting flask<3,>=2.0.3\n",
            "  Downloading Flask-2.2.2-py3-none-any.whl (101 kB)\n",
            "Requirement already satisfied: pyarrow<8,>=6.0.1 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (6.0.1)\n",
            "Requirement already satisfied: numpy<2,>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (1.21.6)\n",
            "Requirement already satisfied: torch<2,>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (1.12.0+cu113)\n",
            "Requirement already satisfied: h5py<4,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (3.1.0)\n",
            "Collecting flask-restful<1,>=0.3.9\n",
            "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
            "Collecting sentence-transformers<3,>=2.2.0\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (4.64.0)\n",
            "Requirement already satisfied: pandas<2,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from clip-retrieval) (1.3.5)\n",
            "Collecting wandb<0.13,>=0.12.10\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting dataclasses<1.0.0,>=0.6\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: opencv-python<5,>=4.5.5.62 in /usr/local/lib/python3.7/dist-packages (from img2dataset) (4.6.0.66)\n",
            "Requirement already satisfied: albumentations<2,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from img2dataset) (1.2.1)\n",
            "Collecting exifread-nocycle<4,>=3.0.1\n",
            "  Downloading ExifRead_nocycle-3.0.1-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (4.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp) (1.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (3.13)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (4.6.0.66)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (0.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (1.7.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (0.18.3)\n",
            "Collecting embedding-reader<2,>=1.2.0\n",
            "  Downloading embedding_reader-1.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip-anytorch<3,>=2.3.1->clip-retrieval) (2022.6.2)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire<0.5.0,>=0.4.0->clip-retrieval) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<0.5.0,>=0.4.0->clip-retrieval) (1.1.0)\n",
            "Collecting click\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from flask<3,>=2.0.3->clip-retrieval) (4.12.0)\n",
            "Collecting Werkzeug>=2.2.2\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting Jinja2>=3.0\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask-restful<1,>=0.3.9->clip-retrieval) (2022.1)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py<4,>=3.1.0->clip-retrieval) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6.0->flask<3,>=2.0.3->clip-retrieval) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3.0->flask<3,>=2.0.3->clip-retrieval) (2.0.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2,>=1.1.5->clip-retrieval) (2.8.2)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations<2,>=1.1.0->img2dataset) (1.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (1.24.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (2021.11.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations<2,>=1.1.0->img2dataset) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations<2,>=1.1.0->img2dataset) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations<2,>=1.1.0->img2dataset) (1.1.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers<3,>=2.2.0->clip-retrieval) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers<3,>=2.2.0->clip-retrieval) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers<3,>=2.2.0->clip-retrieval) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (5.4.8)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (3.17.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb<0.13,>=0.12.10->clip-retrieval) (57.4.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
            "Collecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting caio~=0.9.0\n",
            "  Downloading caio-0.9.7-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (87 kB)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip-anytorch<3,>=2.3.1->clip-retrieval) (0.2.5)\n",
            "Building wheels for collected packages: fire, sentence-transformers, aiofile, pathtools\n",
            "  Building wheel for fire (setup.py): started\n",
            "  Building wheel for fire (setup.py): finished with status 'done'\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=4a03227ea2399cb8e8a1cca53573ece1e3a5ac377b25f21a4e7e4b78e132d4aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "  Building wheel for sentence-transformers (setup.py): started\n",
            "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=33305bb26038582d8363c802abe1674c56165c7586dfc95738fa8e23dca096af\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "  Building wheel for aiofile (setup.py): started\n",
            "  Building wheel for aiofile (setup.py): finished with status 'done'\n",
            "  Created wheel for aiofile: filename=aiofile-3.8.1-py3-none-any.whl size=19450 sha256=995decf6a5ca80bb15586cb455ee2d91b1d9fb9a619807a1e0858184f31b7098\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/2e/eb/8a071ffd66fead648f4da7c14d7d6e231fc22e214cce2250c5\n",
            "  Building wheel for pathtools (setup.py): started\n",
            "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c5bf3fbc5a1b23bd995f8274044ce3338fc190620ee351215cc81334a538c8c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built fire sentence-transformers aiofile pathtools\n",
            "Installing collected packages: urllib3, smmap, requests, PyYAML, MarkupSafe, gitdb, Werkzeug, tokenizers, shortuuid, setproctitle, sentry-sdk, pathtools, Jinja2, itsdangerous, huggingface-hub, GitPython, fsspec, docker-pycreds, click, braceexpand, webdataset, wandb, transformers, sentencepiece, ftfy, flask, fire, faiss-cpu, exifread-nocycle, embedding-reader, dataclasses, aniso8601, sentence-transformers, open-clip-torch, multilingual-clip, img2dataset, flask-restful, flask-cors, clip-anytorch, caio, autofaiss, clip-retrieval, aiomultiprocess, aiofile\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: itsdangerous\n",
            "    Found existing installation: itsdangerous 1.1.0\n",
            "    Uninstalling itsdangerous-1.1.0:\n",
            "      Successfully uninstalled itsdangerous-1.1.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "Successfully installed GitPython-3.1.27 Jinja2-3.1.2 MarkupSafe-2.1.1 PyYAML-6.0 Werkzeug-2.2.2 aiofile-3.8.1 aiomultiprocess-0.9.0 aniso8601-9.0.1 autofaiss-2.15.1 braceexpand-0.1.7 caio-0.9.7 click-8.1.3 clip-anytorch-2.4.0 clip-retrieval-2.34.2 dataclasses-0.6 docker-pycreds-0.4.0 embedding-reader-1.5.0 exifread-nocycle-3.0.1 faiss-cpu-1.7.2 fire-0.4.0 flask-2.2.2 flask-cors-3.0.10 flask-restful-0.3.9 fsspec-2022.1.0 ftfy-6.1.1 gitdb-4.0.9 huggingface-hub-0.8.1 img2dataset-1.32.0 itsdangerous-2.1.2 multilingual-clip-1.0.10 open-clip-torch-1.3.0 pathtools-0.1.2 requests-2.28.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.9.3 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 tokenizers-0.12.1 transformers-4.21.1 urllib3-1.26.11 wandb-0.12.21 webdataset-0.1.103\n",
            "\n",
            "\n",
            "\n",
            "Query returned 1711 results...\n",
            "Progress: 51/1711: 0 fetched, 1 failed, 50 skipped\n",
            "Progress: 102/1711: 0 fetched, 3 failed, 99 skipped\n",
            "Progress: 153/1711: 0 fetched, 7 failed, 146 skipped\n",
            "Progress: 204/1711: 0 fetched, 8 failed, 196 skipped\n",
            "Progress: 255/1711: 0 fetched, 9 failed, 246 skipped\n",
            "Progress: 306/1711: 0 fetched, 9 failed, 297 skipped\n",
            "Progress: 357/1711: 0 fetched, 10 failed, 347 skipped\n",
            "Progress: 408/1711: 0 fetched, 12 failed, 396 skipped\n",
            "Progress: 459/1711: 0 fetched, 14 failed, 445 skipped\n",
            "Progress: 510/1711: 0 fetched, 18 failed, 492 skipped\n",
            "Progress: 561/1711: 1 fetched, 18 failed, 542 skipped\n",
            "Progress: 612/1711: 1 fetched, 18 failed, 593 skipped\n",
            "Progress: 663/1711: 1 fetched, 21 failed, 641 skipped\n",
            "Progress: 714/1711: 1 fetched, 22 failed, 691 skipped\n",
            "Progress: 765/1711: 1 fetched, 25 failed, 739 skipped\n",
            "Progress: 816/1711: 1 fetched, 26 failed, 789 skipped\n",
            "Progress: 867/1711: 1 fetched, 26 failed, 840 skipped\n",
            "Progress: 918/1711: 1 fetched, 27 failed, 890 skipped\n",
            "Progress: 969/1711: 1 fetched, 29 failed, 939 skipped\n",
            "Progress: 1020/1711: 1 fetched, 31 failed, 988 skipped\n",
            "Progress: 1071/1711: 1 fetched, 31 failed, 1039 skipped\n",
            "Progress: 1122/1711: 1 fetched, 36 failed, 1085 skipped\n",
            "Progress: 1173/1711: 2 fetched, 38 failed, 1133 skipped\n",
            "Progress: 1224/1711: 2 fetched, 39 failed, 1183 skipped\n",
            "Progress: 1275/1711: 2 fetched, 42 failed, 1231 skipped\n",
            "Progress: 1326/1711: 3 fetched, 46 failed, 1277 skipped\n",
            "Progress: 1377/1711: 4 fetched, 49 failed, 1324 skipped\n",
            "Progress: 1428/1711: 4 fetched, 51 failed, 1373 skipped\n",
            "Progress: 1479/1711: 5 fetched, 56 failed, 1418 skipped\n",
            "Progress: 1530/1711: 5 fetched, 56 failed, 1469 skipped\n",
            "Progress: 1581/1711: 5 fetched, 59 failed, 1517 skipped\n",
            "Progress: 1632/1711: 5 fetched, 64 failed, 1563 skipped\n",
            "Progress: 1683/1711: 5 fetched, 67 failed, 1611 skipped\n",
            "\n",
            "Done!\n",
            "Generating 6000 cropped squares from source images in /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out...\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4618585751.png because its resolution 270x203 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/3766213478.png because its resolution 300x225 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/3647213474.png because its resolution 267x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4441520057.png because its resolution 300x205 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/321672409.png because its resolution 200x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1126924657.png because its resolution 220x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2146979065.png because its resolution 267x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1085427912.png because its resolution 240x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/7260076.png because its resolution 300x141 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/3780815270.png because its resolution 270x250 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2476472905.png because its resolution 300x198 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2091256299.png because its resolution 413x216 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4105653966.png because its resolution 235x182 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/5376523036.png because its resolution 256x192 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/81546817.png because its resolution 265x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2530686673.png because its resolution 250x250 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/252619746.png because its resolution 267x200 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/636446302.png because its resolution 300x188 is smaller than 256x256!\n",
            "Skipping /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4154590478.png because its resolution 255x255 is smaller than 256x256!\n",
            "\n",
            "Skipped 19 of 45 images... weights for images based on area:\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2007419871.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2764241296.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/5079323448.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4698998000.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/36718094.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/903938593.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1520009253.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4571664650.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1792193321.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2290577591.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2531699235.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/282122905.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1136585873.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4954428552.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4567062594.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1119912784.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4282621117.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/5397807200.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2118870534.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/405366851.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/1926701019.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2968172554.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/3301965256.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4812112919.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/5440258597.png\n",
            "   3.8 /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/2943599031.png\n",
            "\n",
            "WARNING! Output directory exists, make sure this is what you want!\n",
            "\n",
            "Generating random crops...\n",
            "Saved crop 5950/6000 at 50x44 from /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/out/4812112919.png to /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/crop/005950.png\u001b[KDone!\n",
            "Done creating dataset from clip-retrieval in: /content/drive/MyDrive/Disco_Diffusion/Fine_Tuning/spiraldiffusion/dataset/crop\n"
          ]
        }
      ],
      "source": [
        "# create the dataset using clip retrieval and aiohttp/aiomultiprocessing to download in paralell\n",
        "import shlex\n",
        "\n",
        "dataset_text_prompt = \"spiral\" #@param {type: \"string\"}\n",
        "dataset_fetch_size = 5000 #@param {type: \"integer\"}\n",
        "dataset_crop_count = 6000 #@param {type: \"integer\"}\n",
        "force_existing_dataset = True #@param {type: \"boolean\"}\n",
        "\n",
        "datasetPath = f'{datasetRoot}'\n",
        "if pathlib.Path(datasetPath).exists():\n",
        "  print(f\"Dataset directory: {datasetPath}\\nDataset already exists, skipping clip-retrieval...\")\n",
        "else:\n",
        "  createPath(datasetPath)\n",
        "\n",
        "if (not pathlib.Path(datasetPath).exists()) or force_existing_dataset: # or len(list(pathlib.Path(datasetPath).iterdir())) < 3':\n",
        "  print(f\"Creating new dataset from clip-retrieval for the prompt: '{dataset_text_prompt}'\")\n",
        "  try:\n",
        "    datasetOutPath=datasetPath+\"/out\"\n",
        "    createPath(datasetOutPath)\n",
        "    createPath(datasetPath+\"/crop\")\n",
        "\n",
        "    pipi(\"click\", \"clip-retrieval\", \"img2dataset\", \"aiomultiprocess\", \"aiohttp\", \"aiofile\")\n",
        "    wget(\"https://gist.githubusercontent.com/un1tz3r0/a18ba5cf48228ca5cabc58d1d556ad0b/raw/76f36ad320b04e6529d6e68f0cfedae7e8542841/clipfetch.py\", filename=\"clipfetch.py\")\n",
        "    wget(\"https://gist.githubusercontent.com/un1tz3r0/bbada1caa66f0e639e9aa74baec53686/raw/3f91f082030b1aa751d264d6da99e5d4e2cec0be/randomcrops.py\", filename=\"randomcrops.py\")\n",
        "\n",
        "    dataset_text_prompt_q = shlex.quote(dataset_text_prompt)\n",
        "    datasetOutPath_q = shlex.quote(datasetOutPath)\n",
        "    !python3 clipfetch.py $dataset_text_prompt_q $datasetOutPath_q --count $dataset_fetch_size --timeout 5 --paralell 25\n",
        "\n",
        "    print(f\"Generating {dataset_crop_count} cropped squares from source images in {datasetOutPath}...\")\n",
        "\n",
        "    import sys\n",
        "    sys.path.append(pathlib.Path(\"./\").absolute())\n",
        "    import randomcrops\n",
        "    randomcrops.randomcrops(datasetPath+\"/out\", datasetPath+\"/crop\", dataset_crop_count, 256, weighting=0.0, withclasses=False, statusinterval=50)\n",
        "\n",
        "    datasetPath = datasetRoot+\"/crop\"\n",
        "    print(f\"Done creating dataset from clip-retrieval in: {datasetPath}\")\n",
        "    #touch(datasetPath+\"/.completed\")\n",
        "  except Exception as err:\n",
        "    import traceback as tb\n",
        "    tb.print_exc(err)\n",
        "    raise err\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV2gIxZhw2me"
      },
      "source": [
        "# <big><big>Fine Tune</big></big>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqBBkqPjqESf"
      },
      "source": [
        "This will run almost forever, but you should start checking your results at around ~50k iterations. Good results begin to appear at 100-200k iterations, depending on your dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "apH5i0hTqz1y",
        "outputId": "952e7b88-a151-4e47-b6fa-7b69b9e2d09d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-63e7293571cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mMODEL_FLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--image_size 256 --num_channels 128 --num_res_blocks 2 --num_heads 1 --learn_sigma True --use_scale_shift_norm False --attention_resolutions 16\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mDIFFUSION_FLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"--diffusion_steps 1000 --noise_schedule linear --rescale_learned_sigmas False --rescale_timesteps False --use_scale_shift_norm False\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mRESUME_CHECKPOINT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingRoot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{trainingRoot}/lsun_uncond_100M_1200K_bs128.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https://openaipublic.blob.core.windows.net/diffusion/march-2021/lsun_uncond_100M_1200K_bs128.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mTRAIN_FLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"--lr 2e-5 --batch_size 4 --save_interval 1000 --log_interval 50  --resume_checkpoint {shlex.quote(RESUME_CHECKPOINT)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#change to point to your dataset path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainingRoot' is not defined"
          ]
        }
      ],
      "source": [
        "#@markdown # Do the run...\n",
        "\n",
        "import shlex\n",
        "\n",
        "def latest_checkpoint(checkpoint_path, default_model, default_model_url):\n",
        "  import pathlib, os\n",
        "  try:\n",
        "    def kf(f):\n",
        "      return f.lstat().st_mtime\n",
        "    f = str(list(sorted(list(pathlib.Path(checkpoint_path).glob(\"ema_0.9999_*.pt\")), key=kf))[-1])\n",
        "    print(f\"Resuming from latest checkpoint found: {f}\")\n",
        "    return f\n",
        "  except Exception as err:\n",
        "    print(f\"Error finding latest checkpoint in {checkpoint_path}: {err}\")\n",
        "    print(f\"Resuming from default pretrained model: {default_model}\")\n",
        "    if not pathlib.Path(default_model).exists():\n",
        "      print(f\"Downloading default pretrained model from: {default_model_url}\")\n",
        "      wget(default_model_url, filename=default_model)\n",
        "      print(f\"Done!\")\n",
        "    else:\n",
        "      print(f\"Default pretrained model found at: {default_model}\")\n",
        "      print(f\"Skipping model download.\")\n",
        "    return default_model\n",
        "\n",
        "\n",
        "#!wget https://openaipublic.blob.core.windows.net/diffusion/march-2021/lsun_uncond_100M_1200K_bs128.pt\n",
        "MODEL_FLAGS=\"--image_size 256 --num_channels 128 --num_res_blocks 2 --num_heads 1 --learn_sigma True --use_scale_shift_norm False --attention_resolutions 16\"\n",
        "DIFFUSION_FLAGS=\"--diffusion_steps 1000 --noise_schedule linear --rescale_learned_sigmas False --rescale_timesteps False --use_scale_shift_norm False\"\n",
        "RESUME_CHECKPOINT=latest_checkpoint(trainingRoot, f\"{trainingRoot}/lsun_uncond_100M_1200K_bs128.pt\", 'https://openaipublic.blob.core.windows.net/diffusion/march-2021/lsun_uncond_100M_1200K_bs128.pt')\n",
        "TRAIN_FLAGS=f\"--lr 2e-5 --batch_size 4 --save_interval 1000 --log_interval 50  --resume_checkpoint {shlex.quote(RESUME_CHECKPOINT)}\"\n",
        "DATASET_PATH=shlex.quote(datasetPath) #change to point to your dataset path \n",
        "%cd /content/guided-diffusion-sxela\n",
        "!OPENAI_LOGDIR=$trainingRoot python scripts/image_train.py --data_dir $DATASET_PATH $MODEL_FLAGS $DIFFUSION_FLAGS $TRAIN_FLAGS"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Anything Diffusion: Fine-Tuning Your Own Diffusion Model Using CLIP-Retrieval.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}